{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a27c03",
   "metadata": {},
   "source": [
    "## NLP Tutorial - Text Representation: TF-IDF\n",
    "What is TF-IDF?\n",
    "- TF stands for Term Frequency and denotes the ratio of number of times a particular word appeared in a Document to total number of words in the document.\n",
    "\n",
    "   Term Frequency(TF) = [number of times word appeared / total no of words in a document]. \n",
    "   \n",
    "- Term Frequency values ranges between 0 and 1. If a word occurs more number of times, then it's value will be close to 1.\n",
    "\n",
    "- IDF stands for Inverse Document Frequency and denotes the log of ratio of total number of documents/datapoints in the whole dataset to the number of documents that contains the particular word.\n",
    "\n",
    "   Inverse Document Frequency(IDF) = [log(Total number of documents / number of documents that contains the word)].\n",
    "   \n",
    "- In IDF, if a word occured in more number of documents and is common across all documents, then it's value will be less and ratio will approaches to 0.\n",
    "\n",
    "Finally:\n",
    "\n",
    "   TF-IDF = Term Frequency(TF) * Inverse Document Frequency(IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ee02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus=[\n",
    "      \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new surface tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating grapes\"\n",
    "    \"something is amzing\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e14bf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 26, 'eating': 11, 'pizza': 23, 'loki': 18, 'is': 17, 'ironman': 16, 'ate': 8, 'already': 0, 'apple': 6, 'announcing': 5, 'new': 21, 'iphone': 15, 'tomorrow': 27, 'tesla': 25, 'model': 20, 'google': 13, 'pixel': 22, 'microsoft': 19, 'surface': 24, 'amazon': 2, 'eco': 12, 'dot': 10, 'am': 1, 'biryani': 9, 'and': 4, 'you': 28, 'are': 7, 'grapessomething': 14, 'amzing': 3}\n"
     ]
    }
   ],
   "source": [
    "v=TfidfVectorizer()\n",
    "transformed_output=v.fit_transform(corpus)\n",
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85787a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already 2.386294361119891\n",
      "am 2.386294361119891\n",
      "amazon 2.386294361119891\n",
      "amzing 2.386294361119891\n",
      "and 2.386294361119891\n",
      "announcing 1.2876820724517808\n",
      "apple 2.386294361119891\n",
      "are 2.386294361119891\n",
      "ate 2.386294361119891\n",
      "biryani 2.386294361119891\n",
      "dot 2.386294361119891\n",
      "eating 1.9808292530117262\n",
      "eco 2.386294361119891\n",
      "google 2.386294361119891\n",
      "grapessomething 2.386294361119891\n",
      "iphone 2.386294361119891\n",
      "ironman 2.386294361119891\n",
      "is 1.0\n",
      "loki 2.386294361119891\n",
      "microsoft 2.386294361119891\n",
      "model 2.386294361119891\n",
      "new 1.2876820724517808\n",
      "pixel 2.386294361119891\n",
      "pizza 2.386294361119891\n",
      "surface 2.386294361119891\n",
      "tesla 2.386294361119891\n",
      "thor 2.386294361119891\n",
      "tomorrow 1.2876820724517808\n",
      "you 2.386294361119891\n"
     ]
    }
   ],
   "source": [
    "all_feature_names=v.get_feature_names_out()\n",
    "\n",
    "for word in all_feature_names:\n",
    "    index=v.vocabulary_.get(word)\n",
    "    print(f\"{word} {v.idf_[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d84e837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thor eating pizza, Loki is eating pizza, Ironman ate pizza already',\n",
       " 'Apple is announcing new iphone tomorrow']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c29f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24302373, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24302373, 0.        ,\n",
       "        0.        , 0.40346113, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24302373, 0.10184147, 0.24302373, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.72907118, 0.        ,\n",
       "        0.        , 0.24302373, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30902531, 0.57267658, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.57267658, 0.        , 0.23998572, 0.        , 0.        ,\n",
       "        0.        , 0.30902531, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30902531, 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_output.toarray()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c638fe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>Charms Rudraksh American Diamond Gold Meena Om...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19045</th>\n",
       "      <td>Digisol DG-KU1004 Mini USB KVM Switch with Aud...</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21216</th>\n",
       "      <td>NF&amp;E Comfort Memory Foam Keyboard Wrist Rest S...</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>SD Enterprises Sonic Plastic Analogue Wall Clo...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Zacharias Unisex Wool Balaclava/Monkey Cap (Mu...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "6403   Charms Rudraksh American Diamond Gold Meena Om...   \n",
       "19045  Digisol DG-KU1004 Mini USB KVM Switch with Aud...   \n",
       "21216  NF&E Comfort Memory Foam Keyboard Wrist Rest S...   \n",
       "4670   SD Enterprises Sonic Plastic Analogue Wall Clo...   \n",
       "16846  Zacharias Unisex Wool Balaclava/Monkey Cap (Mu...   \n",
       "\n",
       "                        label  \n",
       "6403                Household  \n",
       "19045             Electronics  \n",
       "21216             Electronics  \n",
       "4670                Household  \n",
       "16846  Clothing & Accessories  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"Ecommerce_data.csv\")\n",
    "print(df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c913d64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Household                 6000\n",
       "Electronics               6000\n",
       "Clothing & Accessories    6000\n",
       "Books                     6000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ebd47dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label  \\\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household   \n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household   \n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics   \n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories   \n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          2  \n",
       "3          3  \n",
       "4          3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_num']=df.label.map({\n",
    "    \"Household\":0,\n",
    "    \"Books\":1,\n",
    "    \"Electronics\":2,\n",
    "    \"Clothing & Accessories\":3\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c16122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(df.Text,df.label_num,test_size=0.20,random_state=2022,\n",
    "                                             stratify=df.label_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "087c5c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (19200,)\n",
      "Shape of X_test:  (4800,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6c55c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4800\n",
       "2    4800\n",
       "3    4800\n",
       "1    4800\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be545cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1200\n",
       "2    1200\n",
       "3    1200\n",
       "1    1200\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c078f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1200\n",
      "           1       0.97      0.95      0.96      1200\n",
      "           2       0.97      0.97      0.97      1200\n",
      "           3       0.97      0.98      0.97      1200\n",
      "\n",
      "    accuracy                           0.96      4800\n",
      "   macro avg       0.96      0.96      0.96      4800\n",
      "weighted avg       0.96      0.96      0.96      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipe=Pipeline([\n",
    "    (\"vectorizer\",TfidfVectorizer()),\n",
    "    (\"KNN\",KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cad7bf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20706    Lal Haveli Designer Handmade Patchwork Decorat...\n",
       "19166    GOTOTOP Classical Retro Cotton & PU Leather Ne...\n",
       "15209    FabSeasons Camouflage Polyester Multi Function...\n",
       "2462     Indian Superfoods: Change the Way You Eat Revi...\n",
       "6621     Milton Marvel Insulated Steel Casseroles, Juni...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e121bba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20706    0\n",
       "19166    2\n",
       "15209    3\n",
       "2462     1\n",
       "6621     3\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca544ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa079205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1200\n",
      "           1       0.98      0.92      0.95      1200\n",
      "           2       0.97      0.97      0.97      1200\n",
      "           3       0.97      0.99      0.98      1200\n",
      "\n",
      "    accuracy                           0.96      4800\n",
      "   macro avg       0.96      0.96      0.96      4800\n",
      "weighted avg       0.96      0.96      0.96      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipe=Pipeline([\n",
    "    (\"vectorizer\",TfidfVectorizer()),\n",
    "    (\"Multi NB\",MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57d352e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1200\n",
      "           1       0.98      0.98      0.98      1200\n",
      "           2       0.98      0.97      0.98      1200\n",
      "           3       0.98      0.99      0.99      1200\n",
      "\n",
      "    accuracy                           0.97      4800\n",
      "   macro avg       0.97      0.97      0.97      4800\n",
      "weighted avg       0.97      0.97      0.97      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe=Pipeline([\n",
    "    (\"vectorizer\",TfidfVectorizer()),\n",
    "    (\"R.F.C.\",RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00953cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc=nlp(text)\n",
    "    filtered_tokens=[]\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        \n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "501e72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prepro_tst']=df['Text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c021991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "      <th>prepro_tst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban Ladder Eisner low Study Office Computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "      <td>contrast live Wooden Decorative Box Painted Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2</td>\n",
       "      <td>IO Crest SY PCI40010 PCI raid Host Controller ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>ISAKAA Baby Socks bear 8 Years- Pack 4 6 8 12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>Indira Designer Women Art Mysore Silk Saree Bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label  \\\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household   \n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household   \n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics   \n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories   \n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories   \n",
       "\n",
       "   label_num                                         prepro_tst  \n",
       "0          0  Urban Ladder Eisner low Study Office Computer ...  \n",
       "1          0  contrast live Wooden Decorative Box Painted Bo...  \n",
       "2          2  IO Crest SY PCI40010 PCI raid Host Controller ...  \n",
       "3          3  ISAKAA Baby Socks bear 8 Years- Pack 4 6 8 12 ...  \n",
       "4          3  Indira Designer Women Art Mysore Silk Saree Bl...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84f2d504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Urban Ladder Eisner Low Back Study-Office Computer Chair(Black) A study in simple. The Eisner study chair has a firm foam cushion, which makes long hours at your desk comfortable. The flexible meshed back is designed for air-circulation and support when you lean back. The curved arms provide ergonomic forearm support. Adjust the height using the gas lift to find that comfortable position and the nylon castors make it easy to move around your space. Chrome legs refer to the images for dimension details any assembly required will be done by the UL team at the time of delivery indoor use only.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2045a587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Urban Ladder Eisner low Study Office Computer Chair(Black study simple Eisner study chair firm foam cushion make long hour desk comfortable flexible mesh design air circulation support lean curved arm provide ergonomic forearm support adjust height gas lift find comfortable position nylon castor easy space chrome leg refer image dimension detail assembly require UL team time delivery indoor use'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prepro_tst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51d9b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df.prepro_tst,df.label_num,test_size=0.20,random_state=2022,\n",
    "                                             stratify=df.label_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4b669e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1200\n",
      "           1       0.98      0.98      0.98      1200\n",
      "           2       0.98      0.97      0.98      1200\n",
      "           3       0.98      0.99      0.98      1200\n",
      "\n",
      "    accuracy                           0.98      4800\n",
      "   macro avg       0.98      0.98      0.98      4800\n",
      "weighted avg       0.98      0.98      0.98      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe=Pipeline([\n",
    "    (\"vectorizer\",TfidfVectorizer()),\n",
    "    (\"R.F.C.\",RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170c079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4d93fba",
   "metadata": {},
   "source": [
    "## TF-IDF: Exercises\n",
    "- Humans 👦 show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
    "\n",
    "- In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
    "\n",
    "- For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
    "\n",
    "- We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms.\n",
    "\n",
    "### About Data: Emotion Detection\n",
    "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
    "\n",
    "- This data consists of two columns. - Comment - Emotion\n",
    "\n",
    "- Comment are the statements or messages regarding to a particular event/situation.\n",
    "\n",
    "- Emotion feature tells whether the given comment is fear 😨, Anger 😡, Joy 😂.\n",
    "\n",
    "- As there are only 3 classes, this problem comes under the Multi-Class Classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e45b045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5937, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "#read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
    "df=pd.read_csv(\"Emotion_classify_Data.csv\")\n",
    "\n",
    "#print the shape of dataframe\n",
    "print(df.shape)\n",
    "\n",
    "#print top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a769bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anger    2000\n",
       "joy      2000\n",
       "fear     1937\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of Emotion\n",
    "df.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "383889fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion  Emotion_num\n",
       "0  i seriously hate one subject to death but now ...    fear            1\n",
       "1                 im so full of life i feel appalled   anger            2\n",
       "2  i sit here to write i start to dig out my feel...    fear            1\n",
       "3  ive been really angry with r and i feel like a...     joy            0\n",
       "4  i feel suspicious if there is no one outside l...    fear            1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
    "#joy --> 0, fear --> 1, anger --> 2\n",
    "df['Emotion_num']=df['Emotion'].map({\n",
    "    \"joy\":0,\"fear\":1,\"anger\":2\n",
    "})\n",
    "\n",
    "#checking the results by printing top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452ec23",
   "metadata": {},
   "source": [
    "### Modelling without Pre-processing Text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1219ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20%\n",
    "#Note: Give Random state 2022 and also do the stratify sampling\n",
    "X_train,X_test,y_train,y_test=train_test_split(df.Comment,df.Emotion_num,test_size=0.20,random_state=2022\n",
    "                                               ,stratify=df.Emotion_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06dfffd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (4749,)\n",
      "Shape of X_test: (1188,)\n"
     ]
    }
   ],
   "source": [
    "#print the shapes of X_train and X_test\n",
    "print(\"Shape of X_train:\",X_train.shape)\n",
    "print(\"Shape of X_test:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41720c9",
   "metadata": {},
   "source": [
    "#### Attempt 1 :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "###### Note:\n",
    "\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fde3a865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.27      0.36       400\n",
      "           1       0.37      0.79      0.50       388\n",
      "           2       0.53      0.22      0.31       400\n",
      "\n",
      "    accuracy                           0.42      1188\n",
      "   macro avg       0.49      0.42      0.39      1188\n",
      "weighted avg       0.49      0.42      0.39      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. create a pipeline object\n",
    "pipe=Pipeline([\n",
    "    (\"Countvectorizer\",CountVectorizer(ngram_range=(3,3))),\n",
    "    (\"R.F\",RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6c35d0",
   "metadata": {},
   "source": [
    "### Attempt 2 :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "#### Note:\n",
    "\n",
    "- using CountVectorizer with both unigram and bigrams.\n",
    "- use Multinomial Naive Bayes as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81663150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       400\n",
      "           1       0.87      0.83      0.85       388\n",
      "           2       0.83      0.88      0.85       400\n",
      "\n",
      "    accuracy                           0.86      1188\n",
      "   macro avg       0.86      0.86      0.86      1188\n",
      "weighted avg       0.86      0.86      0.86      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import MultinomialNB from sklearn\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#1. create a pipeline object\n",
    "\n",
    "pipe=Pipeline([\n",
    "    (\"Countvectorizer:\",CountVectorizer(ngram_range=(1,2))),\n",
    "    (\"NB\",MultinomialNB())\n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca0846",
   "metadata": {},
   "source": [
    "### Attempt 3 :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "#### Note:\n",
    "\n",
    "- using CountVectorizer with both unigram and Bigrams.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef8720c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       400\n",
      "           1       0.96      0.88      0.92       388\n",
      "           2       0.93      0.86      0.90       400\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.91      0.90      0.91      1188\n",
      "weighted avg       0.91      0.90      0.91      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "\n",
    "pipe=Pipeline([\n",
    "    (\"Countvectorizer\",CountVectorizer(ngram_range=(1,2))),\n",
    "    (\"R.F\",RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24fd7c",
   "metadata": {},
   "source": [
    "### Attempt 4 :\n",
    "\n",
    "- using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "#### Note:\n",
    "\n",
    "- using TF-IDF vectorizer for Pre-processing the text.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb052fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       400\n",
      "           1       0.92      0.90      0.91       388\n",
      "           2       0.94      0.89      0.91       400\n",
      "\n",
      "    accuracy                           0.91      1188\n",
      "   macro avg       0.92      0.91      0.91      1188\n",
      "weighted avg       0.92      0.91      0.91      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import TfidfVectorizer from sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "\n",
    "pipe=Pipeline([\n",
    "    (\"Countvectorizer\",TfidfVectorizer()),\n",
    "    (\"R.F\",RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cfadfb",
   "metadata": {},
   "source": [
    "### Use text pre-processing to remove stop words, punctuations and apply lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c02df207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "\n",
    "#use this utility function to get the preprocessed text data\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "472249ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column \"preprocessed_comment\" and use the utility function above to get the clean data\n",
    "# this will take some time, please be patient\n",
    "df['preprocessed_comment']=df.Comment.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15c0f843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_num</th>\n",
       "      <th>preprocessed_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>seriously hate subject death feel reluctant drop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "      <td>m life feel appalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>sit write start dig feeling think afraid accep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "      <td>ve angry r feel like idiot trust place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>feel suspicious outside like rapture happen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion  Emotion_num  \\\n",
       "0  i seriously hate one subject to death but now ...    fear            1   \n",
       "1                 im so full of life i feel appalled   anger            2   \n",
       "2  i sit here to write i start to dig out my feel...    fear            1   \n",
       "3  ive been really angry with r and i feel like a...     joy            0   \n",
       "4  i feel suspicious if there is no one outside l...    fear            1   \n",
       "\n",
       "                                preprocessed_comment  \n",
       "0   seriously hate subject death feel reluctant drop  \n",
       "1                               m life feel appalled  \n",
       "2  sit write start dig feeling think afraid accep...  \n",
       "3             ve angry r feel like idiot trust place  \n",
       "4        feel suspicious outside like rapture happen  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30108e47",
   "metadata": {},
   "source": [
    "### Build a model with pre processed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "224ac767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "#Note: Use the preprocessed_Comment\n",
    "X_train,X_test,y_train,y_test=train_test_split(df.preprocessed_comment,df.Emotion_num,test_size=0.20,random_state=2022\n",
    "                                               ,stratify=df.Emotion_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de583ca9",
   "metadata": {},
   "source": [
    "#### Let's check the scores with our best model till now\n",
    "\n",
    "- Random Forest\n",
    "#### Attempt1 :\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "#### Note:\n",
    "\n",
    "- using CountVectorizer with both unigrams and bigrams.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa50d6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       400\n",
      "           1       0.94      0.90      0.92       388\n",
      "           2       0.91      0.94      0.93       400\n",
      "\n",
      "    accuracy                           0.93      1188\n",
      "   macro avg       0.93      0.93      0.93      1188\n",
      "weighted avg       0.93      0.93      0.93      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "pipe=Pipeline([\n",
    "    (\"Countvectorizer\",CountVectorizer(ngram_range=(1,2))),\n",
    "    (\"R.F\",RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357aae08",
   "metadata": {},
   "source": [
    "#### Attempt 2 :\n",
    "\n",
    "- using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "##### Note:\n",
    "\n",
    "- using TF-IDF vectorizer for pre-processing the text.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fc440405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       400\n",
      "           1       0.93      0.92      0.93       388\n",
      "           2       0.94      0.91      0.92       400\n",
      "\n",
      "    accuracy                           0.93      1188\n",
      "   macro avg       0.93      0.93      0.93      1188\n",
      "weighted avg       0.93      0.93      0.93      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "\n",
    "pipe=Pipeline([\n",
    "    (\"Countvectorizer\",TfidfVectorizer()),\n",
    "    (\"R.F\",RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "y_pred=pipe.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4b97b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
